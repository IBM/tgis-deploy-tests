- name: Greedy max new tokens (explicit)
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: a king was
      inputTokenCount: 7
      stopReason: MAX_TOKENS
- name: Greedy include input tokens
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a king
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      inputTokens:
      - text: ▁Once
      - text: ▁upon
      - text: ▁
      - text: a
      - text: ▁time
      - text: ','
      - text: </s>
- name: Greedy include input tokens with logprobs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a king
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      inputTokens:
      - text: ▁Once
        logprob: NaN
      - text: ▁upon
        logprob: NaN
      - text: ▁
        logprob: NaN
      - text: a
        logprob: NaN
      - text: ▁time
        logprob: NaN
      - text: ','
        logprob: NaN
      - text: </s>
        logprob: NaN
- name: Greedy include generated tokens
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a king
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
      - text: a
      - text: ▁
      - text: king
- name: Greedy include generated tokens with logprobs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a king
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
        logprob: -1.7167969
      - text: a
        logprob: -0.09283447
      - text: ▁
        logprob: -2.2558594
      - text: king
        logprob: -1.34375
- name: Greedy multiple inputs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 8
    requests:
    - text: Once upon a time,
    - text: One plus one is
    - text: Somewhere,\nover the rainbow,\nthere is
  response:
    responses:
    - generatedTokenCount: 8
      text: 'a king was a '
      inputTokenCount: 7
      stopReason: MAX_TOKENS
    - generatedTokenCount: 8
      text: a plus one is a plus
      inputTokenCount: 5
      stopReason: MAX_TOKENS
    - generatedTokenCount: 6
      text: a place for everyone
      inputTokenCount: 14
      stopReason: EOS_TOKEN
- name: Greedy multiple inputs include generated tokens, logprobs, and top_n
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 8
      response:
        generatedTokens: true
        tokenLogprobs: true
        topNTokens: 2
    requests:
    - text: Once upon a time,
    - text: One plus one is
    - text: Somewhere,\nover the rainbow,\nthere is
  response:
    responses:
    - generatedTokenCount: 8
      text: 'a king was a '
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
        logprob: -1.7158203
        topTokens:
        - text: ▁
          logprob: -1.7158203
        - text: ▁the
          logprob: -2.8476562
      - text: a
        logprob: -0.0927124
        topTokens:
        - text: a
          logprob: -0.0927124
        - text: king
          logprob: -4.8554688
      - text: ▁
        logprob: -2.2558594
        topTokens:
        - text: ▁
          logprob: -2.2558594
        - text: ▁young
          logprob: -2.6699219
      - text: king
        logprob: -1.34375
        topTokens:
        - text: king
          logprob: -1.34375
        - text: f
          logprob: -2.6132812
      - text: ▁was
        logprob: -2.171875
        topTokens:
        - text: ▁was
          logprob: -2.171875
        - text: ▁had
          logprob: -2.2207031
      - text: ▁
        logprob: -1.7998047
        topTokens:
        - text: ▁
          logprob: -1.7998047
        - text: ▁in
          logprob: -2.6230469
      - text: a
        logprob: -1.4414062
        topTokens:
        - text: a
          logprob: -1.4414062
        - text: crowned
          logprob: -1.671875
      - text: ▁
        logprob: -1.8583984
        topTokens:
        - text: ▁
          logprob: -1.8583984
        - text: ▁man
          logprob: -1.9091797
    - generatedTokenCount: 8
      text: a plus one is a plus
      inputTokenCount: 5
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
        logprob: -2.0195312
        topTokens:
        - text: ▁
          logprob: -2.0195312
        - text: ▁One
          logprob: -2.9042969
      - text: a
        logprob: -1.5449219
        topTokens:
        - text: a
          logprob: -1.5449219
        - text: <unk>
          logprob: -3.21875
      - text: ▁plus
        logprob: -2.96875
        topTokens:
        - text: ▁plus
          logprob: -2.96875
        - text: ▁
          logprob: -3.0117188
      - text: ▁one
        logprob: -1.9140625
        topTokens:
        - text: ▁one
          logprob: -1.9140625
        - text: ▁is
          logprob: -1.9482422
      - text: ▁is
        logprob: -0.7788086
        topTokens:
        - text: ▁is
          logprob: -0.7788086
        - text: </s>
          logprob: -1.3896484
      - text: ▁
        logprob: -1.3867188
        topTokens:
        - text: ▁
          logprob: -1.3867188
        - text: ▁always
          logprob: -2.53125
      - text: a
        logprob: -0.09259033
        topTokens:
        - text: a
          logprob: -0.09259033
        - text: '+1'
          logprob: -4.34375
      - text: ▁plus
        logprob: -0.8120117
        topTokens:
        - text: ▁plus
          logprob: -0.8120117
        - text: ▁positive
          logprob: -2.6074219
    - generatedTokenCount: 6
      text: a place for everyone
      inputTokenCount: 14
      stopReason: EOS_TOKEN
      tokens:
      - text: ▁
        logprob: -1.2675781
        topTokens:
        - text: ▁
          logprob: -1.2675781
        - text: ▁rainbow
          logprob: -2.3144531
      - text: a
        logprob: -0.052337646
        topTokens:
        - text: a
          logprob: -0.052337646
        - text: <unk>
          logprob: -4.0078125
      - text: ▁place
        logprob: -1.2089844
        topTokens:
        - text: ▁place
          logprob: -1.2089844
        - text: ▁rainbow
          logprob: -2.8613281
      - text: ▁for
        logprob: -0.6977539
        topTokens:
        - text: ▁for
          logprob: -0.6977539
        - text: ▁where
          logprob: -2.1269531
      - text: ▁everyone
        logprob: -1.2314453
        topTokens:
        - text: ▁everyone
          logprob: -1.2314453
        - text: ▁you
          logprob: -1.2724609
      - text: </s>
        logprob: -0.3540039
        topTokens:
        - text: </s>
          logprob: -0.3540039
        - text: .
          logprob: -2.2324219
- name: Sample include generated tokens with logprobs, top_k=1
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_k: 1
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a king
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
      - text: a
      - text: ▁
      - text: king
      seed: 99
- name: Sample include input tokens and generated tokens with ranks and top_n, top_k
    < top_n
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_k: 1
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
        generatedTokens: true
        tokenLogprobs: true
        tokenRanks: true
        topNTokens: 2
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a king
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
        rank: 1
        topTokens:
        - text: ▁
      - text: a
        rank: 1
        topTokens:
        - text: a
      - text: ▁
        rank: 1
        topTokens:
        - text: ▁
      - text: king
        rank: 1
        topTokens:
        - text: king
      inputTokens:
      - text: ▁Once
        logprob: NaN
      - text: ▁upon
        logprob: NaN
      - text: ▁
        logprob: NaN
      - text: a
        logprob: NaN
      - text: ▁time
        logprob: NaN
      - text: ','
        logprob: NaN
      - text: </s>
        logprob: NaN
      seed: 99
- name: Sample top_p = 0.000000001
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_p: 0.000000001
      stopping:
        maxNewTokens: 6
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 6
      text: 'a king was '
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      seed: 99
- name: Sample top_k = 10, no seed
  skip_check: true
  request:
    params:
      method: SAMPLE
      sampling:
        top_k: 10
      stopping:
        maxNewTokens: 6
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 6
      text: a girl called Alice came
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      seed: 2818526381
- name: Sample top_p = 0.95, temp = 0.1, top_k = 15, minimum == maximum, no seed
  skip_check: true
  request:
    params:
      method: SAMPLE
      sampling:
        top_p: 0.95
        temperature: 0.1
        top_k: 15
      stopping:
        minNewTokens: 15
        maxNewTokens: 15
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 15
      text: 'a king was a king, and he had '
      inputTokenCount: 7
      stopReason: MAX_TOKENS
      seed: 3857064804
- name: Include input text
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputText: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: "Once upon a time,\n\na king"
      inputTokenCount: 7
      stopReason: MAX_TOKENS
- name: Stop sequence 1 token
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 5
        stopSequences:
        - a
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 2
      text: a
      inputTokenCount: 7
      stopReason: STOP_SEQUENCE
      stopSequence: a
- name: Repetition penalty
  request:
    params:
      method: GREEDY
      decoding:
        repetition_penalty: 2.5
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: a young man was
      inputTokenCount: 7
      stopReason: MAX_TOKENS
- name: Length penalty
  request:
    params:
      method: GREEDY
      decoding:
        repetition_penalty: 2.5
        length_penalty:
          start_index: 8
          decay_factor: 1.01
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: a young man was
      inputTokenCount: 7
      stopReason: MAX_TOKENS
