- name: Greedy max new tokens (explicit)
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: 'a very '
      inputTokenCount: 9
      stopReason: MAX_TOKENS
- name: Greedy include input tokens
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a very
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      inputTokens:
      - text: ▁
      - text: Once
      - text: ▁
      - text: upon
      - text: ▁
      - text: a
      - text: ▁time
      - text: ','
      - text: </s>
- name: Greedy include input tokens with logprobs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a very
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      inputTokens:
      - text: ▁
        logprob: NaN
      - text: Once
        logprob: NaN
      - text: ▁
        logprob: NaN
      - text: upon
        logprob: NaN
      - text: ▁
        logprob: NaN
      - text: a
        logprob: NaN
      - text: ▁time
        logprob: NaN
      - text: ','
        logprob: NaN
      - text: </s>
        logprob: NaN
- name: Greedy include generated tokens
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a very
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
      - text: a
      - text: ▁
      - text: very
- name: Greedy include generated tokens with logprobs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a very
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
        logprob: -1.7939453
      - text: a
        logprob: -0.86816406
      - text: ▁
        logprob: -1.8632812
      - text: very
        logprob: -3.1914062
- name: Greedy multiple inputs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 8
    requests:
    - text: Once upon a time,
    - text: One plus one is
    - text: Somewhere,\nover the rainbow,\nthere is
  response:
    responses:
    - generatedTokenCount: 8
      text: a very famous singer
      inputTokenCount: 9
      stopReason: MAX_TOKENS
    - generatedTokenCount: 2
      text: one
      inputTokenCount: 5
      stopReason: EOS_TOKEN
    - generatedTokenCount: 5
      text: a rainbow
      inputTokenCount: 15
      stopReason: EOS_TOKEN
- name: Greedy multiple inputs include generated tokens, logprobs, and top_n
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 8
      response:
        generatedTokens: true
        tokenLogprobs: true
        topNTokens: 2
    requests:
    - text: Once upon a time,
    - text: One plus one is
    - text: Somewhere,\nover the rainbow,\nthere is
  response:
    responses:
    - generatedTokenCount: 8
      text: a very famous singer
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
        logprob: -1.7919922
        topTokens:
        - text: ▁
          logprob: -1.7919922
        - text: ▁The
          logprob: -2.5976562
      - text: a
        logprob: -0.86621094
        topTokens:
        - text: a
          logprob: -0.86621094
        - text: They
          logprob: -3.4238281
      - text: ▁
        logprob: -1.8632812
        topTokens:
        - text: ▁
          logprob: -1.8632812
        - text: ▁man
          logprob: -2.5351562
      - text: very
        logprob: -3.1953125
        topTokens:
        - text: very
          logprob: -3.1953125
        - text: king
          logprob: -3.2109375
      - text: ▁
        logprob: -1.578125
        topTokens:
        - text: ▁
          logprob: -1.578125
        - text: ▁rich
          logprob: -2.3710938
      - text: famous
        logprob: -1.6875
        topTokens:
        - text: famous
          logprob: -1.6875
        - text: wealth
          logprob: -2.34375
      - text: ▁
        logprob: -1.7080078
        topTokens:
        - text: ▁
          logprob: -1.7080078
        - text: ▁actor
          logprob: -3.4648438
      - text: singer
        logprob: -2.34375
        topTokens:
        - text: singer
          logprob: -2.34375
        - text: actress
          logprob: -2.6015625
    - generatedTokenCount: 2
      text: one
      inputTokenCount: 5
      stopReason: EOS_TOKEN
      tokens:
      - text: ▁one
        logprob: -2.1738281
        topTokens:
        - text: ▁one
          logprob: -2.1738281
        - text: ▁
          logprob: -2.5585938
      - text: </s>
        logprob: -0.56152344
        topTokens:
        - text: </s>
          logprob: -0.56152344
        - text: ▁plus
          logprob: -1.2294922
    - generatedTokenCount: 5
      text: a rainbow
      inputTokenCount: 15
      stopReason: EOS_TOKEN
      tokens:
      - text: ▁
        logprob: -1.8466797
        topTokens:
        - text: ▁
          logprob: -1.8466797
        - text: ▁the
          logprob: -2.3144531
      - text: a
        logprob: -0.32836914
        topTokens:
        - text: a
          logprob: -0.32836914
        - text: heaven
          logprob: -3.6210938
      - text: ▁
        logprob: -1.8505859
        topTokens:
        - text: ▁
          logprob: -1.8505859
        - text: ▁place
          logprob: -1.9990234
      - text: rainbow
        logprob: -1.6660156
        topTokens:
        - text: rainbow
          logprob: -1.6660156
        - text: wonderful
          logprob: -2.1425781
      - text: </s>
        logprob: -0.83984375
        topTokens:
        - text: </s>
          logprob: -0.83984375
        - text: .
          logprob: -1.8320312
- name: Sample include generated tokens with logprobs, top_k=1
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_k: 1
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a very
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
      - text: a
      - text: ▁
      - text: very
      seed: 99
- name: Sample include input tokens and generated tokens with ranks and top_n, top_k
    < top_n
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_k: 1
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
        generatedTokens: true
        tokenLogprobs: true
        tokenRanks: true
        topNTokens: 2
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: a very
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁
        rank: 1
        topTokens:
        - text: ▁
      - text: a
        rank: 1
        topTokens:
        - text: a
      - text: ▁
        rank: 1
        topTokens:
        - text: ▁
      - text: very
        rank: 1
        topTokens:
        - text: very
      inputTokens:
      - text: ▁
        logprob: NaN
      - text: Once
        logprob: NaN
      - text: ▁
        logprob: NaN
      - text: upon
        logprob: NaN
      - text: ▁
        logprob: NaN
      - text: a
        logprob: NaN
      - text: ▁time
        logprob: NaN
      - text: ','
        logprob: NaN
      - text: </s>
        logprob: NaN
      seed: 99
- name: Sample top_p = 0.000000001
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_p: 0.000000001
      stopping:
        maxNewTokens: 6
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 6
      text: a very famous
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      seed: 99
- name: Sample top_k = 10, no seed
  skip_check: true
  request:
    params:
      method: SAMPLE
      sampling:
        top_k: 10
      stopping:
        maxNewTokens: 6
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 6
      text: He went to visit the
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      seed: 4040486501
- name: Sample top_p = 0.95, temp = 0.1, top_k = 15, minimum == maximum, no seed
  skip_check: true
  request:
    params:
      method: SAMPLE
      sampling:
        top_p: 0.95
        temperature: 0.1
        top_k: 15
      stopping:
        minNewTokens: 15
        maxNewTokens: 15
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 15
      text: a very famous singer was a famous singer
      inputTokenCount: 9
      stopReason: MAX_TOKENS
      seed: 2695437119
- name: Include input text
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputText: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: "Once upon a time,\n\na very"
      inputTokenCount: 9
      stopReason: MAX_TOKENS
- name: Stop sequence 1 token
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 5
        stopSequences:
        - a
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 2
      text: a
      inputTokenCount: 9
      stopReason: STOP_SEQUENCE
      stopSequence: a
- name: Repetition penalty
  request:
    params:
      method: GREEDY
      decoding:
        repetition_penalty: 2.5
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: a man was born
      inputTokenCount: 9
      stopReason: MAX_TOKENS
- name: Length penalty
  request:
    params:
      method: GREEDY
      decoding:
        repetition_penalty: 2.5
        length_penalty:
          start_index: 8
          decay_factor: 1.01
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: a man was born
      inputTokenCount: 9
      stopReason: MAX_TOKENS
