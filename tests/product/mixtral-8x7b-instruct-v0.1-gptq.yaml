- name: Greedy max new tokens (explicit)
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: ' there was a young girl'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
- name: Greedy include input tokens
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: ' there was a young'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      inputTokens:
      - text: <s>
      - text: ▁Once
      - text: ▁upon
      - text: ▁a
      - text: ▁time
      - text: ','
- name: Greedy include input tokens with logprobs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: ' there was a young'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      inputTokens:
      - text: <s>
        logprob: NaN
      - text: ▁Once
        logprob: -11.487443
      - text: ▁upon
        logprob: -1.4977863
      - text: ▁a
        logprob: -0.009242369
      - text: ▁time
        logprob: -0.038197245
      - text: ','
        logprob: -0.3875623
- name: Greedy include generated tokens
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: ' there was a young'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁there
      - text: ▁was
      - text: ▁a
      - text: ▁young
- name: Greedy include generated tokens with logprobs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: ' there was a young'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁there
        logprob: -1.800834
      - text: ▁was
        logprob: -0.17661428
      - text: ▁a
        logprob: -0.1523437
      - text: ▁young
        logprob: -2.4111445
- name: Greedy multiple inputs
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 8
    requests:
    - text: Once upon a time,
    - text: One plus one is
    - text: Somewhere,\nover the rainbow,\nthere is
  response:
    responses:
    - generatedTokenCount: 8
      text: ' there was a young girl who loved to'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
    - generatedTokenCount: 8
      inputTokenCount: 5
      stopReason: MAX_TOKENS
    - generatedTokenCount: 8
      text: ' a land of\nchocolate,\'
      inputTokenCount: 13
      stopReason: MAX_TOKENS
- name: Greedy multiple inputs include generated tokens, logprobs, and top_n
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 8
      response:
        generatedTokens: true
        tokenLogprobs: true
        topNTokens: 2
    requests:
    - text: Once upon a time,
    - text: One plus one is
    - text: Somewhere,\nover the rainbow,\nthere is
  response:
    responses:
    - generatedTokenCount: 8
      text: ' there was a young girl who loved to'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁there
        logprob: -1.7976997
        topTokens:
        - text: ▁there
          logprob: -1.7976997
        - text: ▁in
          logprob: -1.8914497
      - text: ▁was
        logprob: -0.17637378
        topTokens:
        - text: ▁was
          logprob: -0.17637378
        - text: ▁were
          logprob: -2.3169987
      - text: ▁a
        logprob: -0.15104775
        topTokens:
        - text: ▁a
          logprob: -0.15104775
        - text: ▁an
          logprob: -2.9166727
      - text: ▁young
        logprob: -2.4152913
        topTokens:
        - text: ▁young
          logprob: -2.4152913
        - text: ▁girl
          logprob: -2.6652913
      - text: ▁girl
        logprob: -1.5906967
        topTokens:
        - text: ▁girl
          logprob: -1.5906967
        - text: ▁man
          logprob: -1.8094467
      - text: ▁who
        logprob: -0.9773375
        topTokens:
        - text: ▁who
          logprob: -0.9773375
        - text: ▁named
          logprob: -1.1648375
      - text: ▁loved
        logprob: -1.7837679
        topTokens:
        - text: ▁loved
          logprob: -1.7837679
        - text: ▁was
          logprob: -1.8931429
      - text: ▁to
        logprob: -0.6443131
        topTokens:
        - text: ▁to
          logprob: -0.6443131
        - text: ▁the
          logprob: -3.284938
    - generatedTokenCount: 8
      inputTokenCount: 5
      stopReason: MAX_TOKENS
      tokens:
      - text: <unk>
        logprob: NaN
      - text: <unk>
        logprob: NaN
      - text: <unk>
        logprob: NaN
      - text: <unk>
        logprob: NaN
      - text: <unk>
        logprob: NaN
      - text: <unk>
        logprob: NaN
      - text: <unk>
        logprob: NaN
      - text: <unk>
        logprob: NaN
    - generatedTokenCount: 8
      text: ' a land of\nchocolate,\'
      inputTokenCount: 13
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁a
        logprob: -0.17400825
        topTokens:
        - text: ▁a
          logprob: -0.17400825
        - text: ▁an
          logprob: -3.9240084
      - text: ▁land
        logprob: -1.5699322
        topTokens:
        - text: ▁land
          logprob: -1.5699322
        - text: ▁place
          logprob: -2.1793072
      - text: ▁of
        logprob: -1.2395077
        topTokens:
        - text: ▁of
          logprob: -1.2395077
        - text: ▁where
          logprob: -1.5207577
      - text: \
        logprob: -2.0458517
        topTokens:
        - text: \
          logprob: -2.0458517
        - text: ▁what
          logprob: -2.1864767
      - text: n
        logprob: -0.28526753
        topTokens:
        - text: n
          logprob: -0.28526753
        - text: ns
          logprob: -1.8633926
      - text: ch
        logprob: -2.5403461
        topTokens:
        - text: ch
          logprob: -2.5403461
        - text: \
          logprob: -3.5872211
      - text: ocolate
        logprob: -0.14343768
        topTokens:
        - text: ocolate
          logprob: -0.14343768
        - text: ocol
          logprob: -2.7684376
      - text: ',\'
        logprob: -1.7749884
        topTokens:
        - text: ',\'
          logprob: -1.7749884
        - text: .\
          logprob: -1.8921759
- name: Sample include generated tokens with logprobs, top_k=1
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_k: 1
      stopping:
        maxNewTokens: 4
      response:
        generatedTokens: true
        tokenLogprobs: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: ' there was a young'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁there
      - text: ▁was
      - text: ▁a
      - text: ▁young
      seed: 99
- name: Sample include input tokens and generated tokens with ranks and top_n, top_k
    < top_n
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_k: 1
      stopping:
        maxNewTokens: 4
      response:
        inputTokens: true
        generatedTokens: true
        tokenLogprobs: true
        tokenRanks: true
        topNTokens: 2
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: ' there was a young'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      tokens:
      - text: ▁there
        rank: 1
        topTokens:
        - text: ▁there
      - text: ▁was
        rank: 1
        topTokens:
        - text: ▁was
      - text: ▁a
        rank: 1
        topTokens:
        - text: ▁a
      - text: ▁young
        rank: 1
        topTokens:
        - text: ▁young
      inputTokens:
      - text: <s>
        logprob: NaN
      - text: ▁Once
        logprob: -11.483853
        rank: 487
        topTokens:
        - text: ▁Q
          logprob: -1.0346345
        - text: ▁Question
          logprob: -1.0346345
      - text: ▁upon
        logprob: -1.492244
        rank: 1
        topTokens:
        - text: ▁upon
          logprob: -1.492244
        - text: ▁you
          logprob: -1.726619
      - text: ▁a
        logprob: -0.009240716
        rank: 1
        topTokens:
        - text: ▁a
          logprob: -0.009240716
        - text: ▁an
          logprob: -5.5873656
      - text: ▁time
        logprob: -0.03775126
        rank: 1
        topTokens:
        - text: ▁time
          logprob: -0.03775126
        - text: ▁midnight
          logprob: -4.740876
      - text: ','
        logprob: -0.3850549
        rank: 1
        topTokens:
        - text: ','
          logprob: -0.3850549
        - text: ▁in
          logprob: -2.4163048
      seed: 99
- name: Sample top_p = 0.000000001
  request:
    params:
      method: SAMPLE
      sampling:
        seed: 99
        top_p: 0.000000001
      stopping:
        maxNewTokens: 6
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 6
      text: ' there was a young girl who'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      seed: 99
- name: Sample top_k = 10, no seed
  skip_check: true
  request:
    params:
      method: SAMPLE
      sampling:
        top_k: 10
      stopping:
        maxNewTokens: 6
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 6
      text: ' there was only one way to'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      seed: 2410558213
- name: Sample top_p = 0.95, temp = 0.1, top_k = 15, minimum == maximum, no seed
  skip_check: true
  request:
    params:
      method: SAMPLE
      sampling:
        top_p: 0.95
        temperature: 0.1
        top_k: 15
      stopping:
        minNewTokens: 15
        maxNewTokens: 15
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 15
      text: ' there was a girl who loved to read. She read everything she could get'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
      seed: 411709214
- name: Include input text
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 4
      response:
        inputText: true
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 4
      text: Once upon a time, there was a young
      inputTokenCount: 6
      stopReason: MAX_TOKENS
- name: Stop sequence 1 token
  request:
    params:
      method: GREEDY
      stopping:
        maxNewTokens: 5
        stopSequences:
        - a
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 2
      text: ' there wa'
      inputTokenCount: 6
      stopReason: STOP_SEQUENCE
      stopSequence: a
- name: Repetition penalty
  request:
    params:
      method: GREEDY
      decoding:
        repetition_penalty: 2.5
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: ' there was an old man'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
- name: Length penalty
  request:
    params:
      method: GREEDY
      decoding:
        repetition_penalty: 2.5
        length_penalty:
          start_index: 8
          decay_factor: 1.01
      stopping:
        maxNewTokens: 5
    requests:
    - text: Once upon a time,
  response:
    responses:
    - generatedTokenCount: 5
      text: ' there was an old man'
      inputTokenCount: 6
      stopReason: MAX_TOKENS
